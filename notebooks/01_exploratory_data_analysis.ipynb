{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f4045df",
   "metadata": {},
   "source": [
    "# Employee Salary Prediction - Exploratory Data Analysis\n",
    "\n",
    "This notebook performs comprehensive exploratory data analysis on employee salary data to understand patterns, relationships, and insights that will guide our machine learning model development.\n",
    "\n",
    "## Objectives:\n",
    "- Understand the dataset structure and characteristics\n",
    "- Identify patterns and trends in employee salaries\n",
    "- Explore relationships between different features\n",
    "- Detect potential issues (outliers, missing values, data quality)\n",
    "- Generate insights to inform feature engineering and model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0661ebad",
   "metadata": {},
   "source": [
    "## 1. Install and Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0589fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if not already installed\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install a package using pip\"\"\"\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"‚úì {package} installed successfully\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(f\"‚úó Failed to install {package}\")\n",
    "\n",
    "# List of required packages\n",
    "required_packages = [\n",
    "    'pandas', 'numpy', 'matplotlib', 'seaborn', 'plotly', \n",
    "    'scikit-learn', 'jupyter', 'joblib'\n",
    "]\n",
    "\n",
    "# Install packages\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"‚úì {package} already installed\")\n",
    "    except ImportError:\n",
    "        install_package(package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7405cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add src directory to path for importing custom modules\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Configure seaborn\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úì All libraries imported successfully!\")\n",
    "print(\"‚úì Configuration complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe07504",
   "metadata": {},
   "source": [
    "## 2. Set Up Project Directory Structure and Generate Sample Data\n",
    "\n",
    "First, let's ensure our project structure is properly set up and generate sample data if it doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7372f02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create project directory structure\n",
    "import os\n",
    "\n",
    "# Define project directories\n",
    "directories = [\n",
    "    '../data',\n",
    "    '../models',\n",
    "    '../src',\n",
    "    '../notebooks'\n",
    "]\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for directory in directories:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"‚úì Created directory: {directory}\")\n",
    "    else:\n",
    "        print(f\"‚úì Directory already exists: {directory}\")\n",
    "\n",
    "# Generate sample data if it doesn't exist\n",
    "data_file = '../data/employee_salary_data.csv'\n",
    "\n",
    "if not os.path.exists(data_file):\n",
    "    print(\"\\nüìä Generating sample employee salary data...\")\n",
    "    \n",
    "    # Set random seed for reproducibility\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Define possible values for categorical variables\n",
    "    departments = ['Engineering', 'Sales', 'Marketing', 'HR', 'Finance', 'Operations', 'IT']\n",
    "    job_titles = ['Junior', 'Mid-Level', 'Senior', 'Lead', 'Manager', 'Director']\n",
    "    education_levels = ['Bachelor', 'Master', 'PhD', 'High School']\n",
    "    locations = ['New York', 'San Francisco', 'Chicago', 'Austin', 'Boston', 'Seattle', 'Remote']\n",
    "    \n",
    "    # Generate sample data\n",
    "    n_samples = 1000\n",
    "    \n",
    "    data = {\n",
    "        'employee_id': range(1, n_samples + 1),\n",
    "        'age': np.random.randint(22, 65, n_samples),\n",
    "        'years_experience': np.random.randint(0, 35, n_samples),\n",
    "        'department': np.random.choice(departments, n_samples),\n",
    "        'job_title': np.random.choice(job_titles, n_samples),\n",
    "        'education_level': np.random.choice(education_levels, n_samples),\n",
    "        'location': np.random.choice(locations, n_samples),\n",
    "        'performance_rating': np.random.uniform(1, 5, n_samples).round(2),\n",
    "        'overtime_hours': np.random.randint(0, 20, n_samples),\n",
    "        'projects_completed': np.random.randint(0, 15, n_samples),\n",
    "    }\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Create realistic salary based on multiple factors\n",
    "    base_salary = 40000\n",
    "    \n",
    "    # Department multiplier\n",
    "    dept_multiplier = {\n",
    "        'Engineering': 1.4, 'IT': 1.3, 'Finance': 1.2, \n",
    "        'Sales': 1.1, 'Marketing': 1.0, 'HR': 0.9, 'Operations': 0.8\n",
    "    }\n",
    "    \n",
    "    # Job title multiplier\n",
    "    title_multiplier = {\n",
    "        'Junior': 1.0, 'Mid-Level': 1.3, 'Senior': 1.6, \n",
    "        'Lead': 1.9, 'Manager': 2.2, 'Director': 2.8\n",
    "    }\n",
    "    \n",
    "    # Education multiplier\n",
    "    edu_multiplier = {\n",
    "        'High School': 1.0, 'Bachelor': 1.2, 'Master': 1.4, 'PhD': 1.6\n",
    "    }\n",
    "    \n",
    "    # Location multiplier\n",
    "    loc_multiplier = {\n",
    "        'New York': 1.3, 'San Francisco': 1.4, 'Seattle': 1.2, \n",
    "        'Boston': 1.2, 'Chicago': 1.1, 'Austin': 1.0, 'Remote': 0.9\n",
    "    }\n",
    "    \n",
    "    # Calculate salary with multiple factors\n",
    "    df['salary'] = (\n",
    "        base_salary * \n",
    "        df['department'].map(dept_multiplier) *\n",
    "        df['job_title'].map(title_multiplier) *\n",
    "        df['education_level'].map(edu_multiplier) *\n",
    "        df['location'].map(loc_multiplier) *\n",
    "        (1 + df['years_experience'] * 0.03) *\n",
    "        (1 + df['performance_rating'] * 0.1) *\n",
    "        (1 + df['overtime_hours'] * 0.02) *\n",
    "        (1 + df['projects_completed'] * 0.05)\n",
    "    ).round(0).astype(int)\n",
    "    \n",
    "    # Add some random noise to make it more realistic\n",
    "    df['salary'] += np.random.normal(0, 5000, n_samples).astype(int)\n",
    "    \n",
    "    # Ensure minimum salary\n",
    "    df['salary'] = np.maximum(df['salary'], 35000)\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(data_file, index=False)\n",
    "    print(f\"‚úì Sample data generated and saved to {data_file}\")\n",
    "    print(f\"‚úì Dataset shape: {df.shape}\")\n",
    "else:\n",
    "    print(f\"‚úì Data file already exists: {data_file}\")\n",
    "\n",
    "print(\"\\nüéâ Project setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e07833",
   "metadata": {},
   "source": [
    "## 3. Load and Explore the Dataset\n",
    "\n",
    "Let's load the employee salary dataset and perform initial exploration to understand its structure and characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422a620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../data/employee_salary_data.csv')\n",
    "\n",
    "print(\"üìä DATASET OVERVIEW\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"Number of Rows: {df.shape[0]:,}\")\n",
    "print(f\"Number of Columns: {df.shape[1]}\")\n",
    "print(f\"Memory Usage: {df.memory_usage(deep=True).sum() / 1024:.2f} KB\")\n",
    "\n",
    "print(\"\\nüìã COLUMN INFORMATION\")\n",
    "print(\"=\" * 50)\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    dtype = df[col].dtype\n",
    "    unique_count = df[col].nunique()\n",
    "    null_count = df[col].isnull().sum()\n",
    "    print(f\"{i:2d}. {col:<20} | {str(dtype):<10} | Unique: {unique_count:4d} | Nulls: {null_count:3d}\")\n",
    "\n",
    "print(\"\\nüìà FIRST 5 ROWS\")\n",
    "print(\"=\" * 50)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed269500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary of numerical columns\n",
    "print(\"üìä STATISTICAL SUMMARY - NUMERICAL COLUMNS\")\n",
    "print(\"=\" * 80)\n",
    "numerical_summary = df.describe()\n",
    "print(numerical_summary)\n",
    "\n",
    "print(\"\\nüìä STATISTICAL SUMMARY - CATEGORICAL COLUMNS\")\n",
    "print(\"=\" * 80)\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col.upper()}:\")\n",
    "    print(f\"  Unique values: {df[col].nunique()}\")\n",
    "    print(f\"  Most common: {df[col].value_counts().head(3).to_dict()}\")\n",
    "\n",
    "print(\"\\nüîç DATA QUALITY CHECK\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Missing Values:\")\n",
    "missing_values = df.isnull().sum()\n",
    "if missing_values.sum() == 0:\n",
    "    print(\"‚úì No missing values found!\")\n",
    "else:\n",
    "    print(missing_values[missing_values > 0])\n",
    "\n",
    "print(\"\\nDuplicate Rows:\")\n",
    "duplicate_count = df.duplicated().sum()\n",
    "if duplicate_count == 0:\n",
    "    print(\"‚úì No duplicate rows found!\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  {duplicate_count} duplicate rows found\")\n",
    "\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310c8acb",
   "metadata": {},
   "source": [
    "## 4. Data Visualization and Distribution Analysis\n",
    "\n",
    "Let's create comprehensive visualizations to understand the distribution of our data and identify patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebad8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salary Distribution Analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Salary Distribution Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Histogram of Salary\n",
    "axes[0,0].hist(df['salary'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0,0].set_title('Salary Distribution')\n",
    "axes[0,0].set_xlabel('Salary ($)')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "axes[0,0].axvline(df['salary'].mean(), color='red', linestyle='--', label=f'Mean: ${df[\"salary\"].mean():,.0f}')\n",
    "axes[0,0].axvline(df['salary'].median(), color='green', linestyle='--', label=f'Median: ${df[\"salary\"].median():,.0f}')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Box Plot of Salary\n",
    "axes[0,1].boxplot(df['salary'])\n",
    "axes[0,1].set_title('Salary Box Plot')\n",
    "axes[0,1].set_ylabel('Salary ($)')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Age Distribution\n",
    "axes[1,0].hist(df['age'], bins=20, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "axes[1,0].set_title('Age Distribution')\n",
    "axes[1,0].set_xlabel('Age')\n",
    "axes[1,0].set_ylabel('Frequency')\n",
    "axes[1,0].axvline(df['age'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"age\"].mean():.1f}')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Years of Experience Distribution\n",
    "axes[1,1].hist(df['years_experience'], bins=20, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "axes[1,1].set_title('Years of Experience Distribution')\n",
    "axes[1,1].set_xlabel('Years of Experience')\n",
    "axes[1,1].set_ylabel('Frequency')\n",
    "axes[1,1].axvline(df['years_experience'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"years_experience\"].mean():.1f}')\n",
    "axes[1,1].legend()\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print salary statistics\n",
    "print(\"üí∞ SALARY STATISTICS\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Mean Salary:     ${df['salary'].mean():,.2f}\")\n",
    "print(f\"Median Salary:   ${df['salary'].median():,.2f}\")\n",
    "print(f\"Min Salary:      ${df['salary'].min():,.2f}\")\n",
    "print(f\"Max Salary:      ${df['salary'].max():,.2f}\")\n",
    "print(f\"Std Deviation:   ${df['salary'].std():,.2f}\")\n",
    "print(f\"25th Percentile: ${df['salary'].quantile(0.25):,.2f}\")\n",
    "print(f\"75th Percentile: ${df['salary'].quantile(0.75):,.2f}\")\n",
    "print(f\"IQR:             ${df['salary'].quantile(0.75) - df['salary'].quantile(0.25):,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88143d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Variables Analysis\n",
    "categorical_cols = ['department', 'job_title', 'education_level', 'location']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 15))\n",
    "fig.suptitle('Categorical Variables Distribution', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, col in enumerate(categorical_cols):\n",
    "    row = i // 2\n",
    "    col_idx = i % 2\n",
    "    \n",
    "    # Count plot\n",
    "    value_counts = df[col].value_counts()\n",
    "    axes[row, col_idx].bar(value_counts.index, value_counts.values, alpha=0.7)\n",
    "    axes[row, col_idx].set_title(f'{col.replace(\"_\", \" \").title()} Distribution')\n",
    "    axes[row, col_idx].set_ylabel('Count')\n",
    "    axes[row, col_idx].tick_params(axis='x', rotation=45)\n",
    "    axes[row, col_idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for j, v in enumerate(value_counts.values):\n",
    "        axes[row, col_idx].text(j, v + 5, str(v), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print categorical statistics\n",
    "print(\"üìä CATEGORICAL VARIABLES SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col.upper().replace('_', ' ')}:\")\n",
    "    print(f\"  Unique values: {df[col].nunique()}\")\n",
    "    print(f\"  Most common: {df[col].mode().iloc[0]} ({df[col].value_counts().iloc[0]} occurrences)\")\n",
    "    print(f\"  Distribution: {dict(df[col].value_counts().head(3))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1354b07",
   "metadata": {},
   "source": [
    "## 5. Correlation Analysis and Feature Relationships\n",
    "\n",
    "Let's analyze the relationships between different features and their correlation with salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9739c6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix for Numerical Variables\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = df[numerical_cols].corr()\n",
    "\n",
    "# Create correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, \n",
    "            annot=True, \n",
    "            cmap='coolwarm', \n",
    "            center=0,\n",
    "            square=True, \n",
    "            mask=mask,\n",
    "            fmt='.2f', \n",
    "            cbar_kws={\"shrink\": .8})\n",
    "plt.title('Correlation Matrix - Numerical Variables', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print strongest correlations with salary\n",
    "print(\"üîó STRONGEST CORRELATIONS WITH SALARY\")\n",
    "print(\"=\" * 50)\n",
    "salary_corr = correlation_matrix['salary'].abs().sort_values(ascending=False)[1:]  # Exclude self-correlation\n",
    "for feature, corr in salary_corr.items():\n",
    "    print(f\"{feature:<20}: {corr:.3f}\")\n",
    "\n",
    "# Scatter plots for key relationships\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Key Relationships with Salary', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Years Experience vs Salary\n",
    "axes[0,0].scatter(df['years_experience'], df['salary'], alpha=0.6, color='blue')\n",
    "axes[0,0].set_xlabel('Years of Experience')\n",
    "axes[0,0].set_ylabel('Salary ($)')\n",
    "axes[0,0].set_title('Experience vs Salary')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add trend line\n",
    "z = np.polyfit(df['years_experience'], df['salary'], 1)\n",
    "p = np.poly1d(z)\n",
    "axes[0,0].plot(df['years_experience'], p(df['years_experience']), \"r--\", alpha=0.8)\n",
    "\n",
    "# 2. Age vs Salary\n",
    "axes[0,1].scatter(df['age'], df['salary'], alpha=0.6, color='green')\n",
    "axes[0,1].set_xlabel('Age')\n",
    "axes[0,1].set_ylabel('Salary ($)')\n",
    "axes[0,1].set_title('Age vs Salary')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add trend line\n",
    "z = np.polyfit(df['age'], df['salary'], 1)\n",
    "p = np.poly1d(z)\n",
    "axes[0,1].plot(df['age'], p(df['age']), \"r--\", alpha=0.8)\n",
    "\n",
    "# 3. Performance Rating vs Salary\n",
    "axes[1,0].scatter(df['performance_rating'], df['salary'], alpha=0.6, color='orange')\n",
    "axes[1,0].set_xlabel('Performance Rating')\n",
    "axes[1,0].set_ylabel('Salary ($)')\n",
    "axes[1,0].set_title('Performance Rating vs Salary')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add trend line\n",
    "z = np.polyfit(df['performance_rating'], df['salary'], 1)\n",
    "p = np.poly1d(z)\n",
    "axes[1,0].plot(df['performance_rating'], p(df['performance_rating']), \"r--\", alpha=0.8)\n",
    "\n",
    "# 4. Projects Completed vs Salary\n",
    "axes[1,1].scatter(df['projects_completed'], df['salary'], alpha=0.6, color='purple')\n",
    "axes[1,1].set_xlabel('Projects Completed')\n",
    "axes[1,1].set_ylabel('Salary ($)')\n",
    "axes[1,1].set_title('Projects Completed vs Salary')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add trend line\n",
    "z = np.polyfit(df['projects_completed'], df['salary'], 1)\n",
    "p = np.poly1d(z)\n",
    "axes[1,1].plot(df['projects_completed'], p(df['projects_completed']), \"r--\", alpha=0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f095fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salary Analysis by Categorical Variables\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 15))\n",
    "fig.suptitle('Salary Analysis by Categorical Variables', fontsize=16, fontweight='bold')\n",
    "\n",
    "categorical_cols = ['department', 'job_title', 'education_level', 'location']\n",
    "\n",
    "for i, col in enumerate(categorical_cols):\n",
    "    row = i // 2\n",
    "    col_idx = i % 2\n",
    "    \n",
    "    # Calculate mean salary by category\n",
    "    salary_by_category = df.groupby(col)['salary'].agg(['mean', 'median', 'count']).sort_values('mean', ascending=False)\n",
    "    \n",
    "    # Create box plot\n",
    "    df.boxplot(column='salary', by=col, ax=axes[row, col_idx])\n",
    "    axes[row, col_idx].set_title(f'Salary by {col.replace(\"_\", \" \").title()}')\n",
    "    axes[row, col_idx].set_xlabel(col.replace(\"_\", \" \").title())\n",
    "    axes[row, col_idx].set_ylabel('Salary ($)')\n",
    "    axes[row, col_idx].tick_params(axis='x', rotation=45)\n",
    "    axes[row, col_idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed salary statistics by category\n",
    "print(\"üí∞ SALARY ANALYSIS BY CATEGORICAL VARIABLES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col.upper().replace('_', ' ')}:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    salary_stats = df.groupby(col)['salary'].agg(['mean', 'median', 'std', 'count']).round(2)\n",
    "    salary_stats = salary_stats.sort_values('mean', ascending=False)\n",
    "    \n",
    "    print(f\"{'Category':<15} | {'Mean':<10} | {'Median':<10} | {'Std':<10} | {'Count':<8}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for category, stats in salary_stats.iterrows():\n",
    "        print(f\"{category:<15} | ${stats['mean']:>8,.0f} | ${stats['median']:>8,.0f} | ${stats['std']:>8,.0f} | {stats['count']:>5.0f}\")\n",
    "    \n",
    "    # Calculate the range (difference between highest and lowest mean)\n",
    "    salary_range = salary_stats['mean'].max() - salary_stats['mean'].min()\n",
    "    print(f\"\\nSalary Range: ${salary_range:,.0f} (difference between highest and lowest mean)\")\n",
    "    \n",
    "    # Show percentage difference\n",
    "    pct_diff = ((salary_stats['mean'].max() - salary_stats['mean'].min()) / salary_stats['mean'].min()) * 100\n",
    "    print(f\"Percentage Difference: {pct_diff:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28efbf6",
   "metadata": {},
   "source": [
    "## 6. Outlier Detection and Data Quality Assessment\n",
    "\n",
    "Let's identify potential outliers and assess the overall data quality for our machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efbe51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Salary Analysis with Visualizations\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Create a figure with multiple subplots for salary analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('üîç Comprehensive Salary Distribution Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Histogram with statistics\n",
    "axes[0,0].hist(df['salary'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0,0].set_title('Salary Distribution')\n",
    "axes[0,0].set_xlabel('Salary ($)')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "axes[0,0].axvline(df['salary'].mean(), color='red', linestyle='--', label=f'Mean: ${df[\"salary\"].mean():,.0f}')\n",
    "axes[0,0].axvline(df['salary'].median(), color='green', linestyle='--', label=f'Median: ${df[\"salary\"].median():,.0f}')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Box plot for outlier detection\n",
    "axes[0,1].boxplot(df['salary'])\n",
    "axes[0,1].set_title('Salary Box Plot (Outlier Detection)')\n",
    "axes[0,1].set_ylabel('Salary ($)')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Q-Q plot for normality test\n",
    "stats.probplot(df['salary'], dist=\"norm\", plot=axes[1,0])\n",
    "axes[1,0].set_title('Q-Q Plot (Normality Test)')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Salary by Department\n",
    "df.boxplot(column='salary', by='department', ax=axes[1,1])\n",
    "axes[1,1].set_title('Salary by Department')\n",
    "axes[1,1].set_xlabel('Department')\n",
    "axes[1,1].set_ylabel('Salary ($)')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed salary statistics\n",
    "print(\"üìä DETAILED SALARY STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Mean Salary: ${df['salary'].mean():,.2f}\")\n",
    "print(f\"Median Salary: ${df['salary'].median():,.2f}\")\n",
    "print(f\"Standard Deviation: ${df['salary'].std():,.2f}\")\n",
    "print(f\"Minimum Salary: ${df['salary'].min():,.2f}\")\n",
    "print(f\"Maximum Salary: ${df['salary'].max():,.2f}\")\n",
    "print(f\"Range: ${df['salary'].max() - df['salary'].min():,.2f}\")\n",
    "print(f\"Coefficient of Variation: {df['salary'].std() / df['salary'].mean():.3f}\")\n",
    "print(f\"Skewness: {df['salary'].skew():.3f}\")\n",
    "print(f\"Kurtosis: {df['salary'].kurtosis():.3f}\")\n",
    "\n",
    "# Percentile analysis\n",
    "percentiles = [10, 25, 50, 75, 90, 95, 99]\n",
    "print(f\"\\nüìà PERCENTILE ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "for p in percentiles:\n",
    "    value = np.percentile(df['salary'], p)\n",
    "    print(f\"  {p:2d}th percentile: ${value:8,.0f}\")\n",
    "\n",
    "# Outlier detection using IQR method\n",
    "Q1 = df['salary'].quantile(0.25)\n",
    "Q3 = df['salary'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "outliers = df[(df['salary'] < lower_bound) | (df['salary'] > upper_bound)]\n",
    "\n",
    "print(f\"\\nüö® OUTLIER DETECTION (IQR Method)\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Lower Bound: ${lower_bound:,.2f}\")\n",
    "print(f\"Upper Bound: ${upper_bound:,.2f}\")\n",
    "print(f\"Number of Outliers: {len(outliers)}\")\n",
    "print(f\"Percentage of Outliers: {len(outliers)/len(df)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17370d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Analysis\n",
    "print(\"üîó CORRELATION ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create correlation matrix for numerical features\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = df[numerical_cols].corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, fmt='.2f', cbar_kws={\"shrink\": .8})\n",
    "plt.title('üî• Feature Correlation Matrix', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print correlation with salary\n",
    "salary_corr = correlation_matrix['salary'].sort_values(ascending=False)\n",
    "print(\"\\nüìä CORRELATION WITH SALARY\")\n",
    "print(\"=\" * 40)\n",
    "for feature, corr_value in salary_corr.items():\n",
    "    if feature != 'salary':\n",
    "        strength = \"Very Strong\" if abs(corr_value) > 0.8 else \"Strong\" if abs(corr_value) > 0.6 else \"Moderate\" if abs(corr_value) > 0.4 else \"Weak\"\n",
    "        direction = \"Positive\" if corr_value > 0 else \"Negative\"\n",
    "        print(f\"{feature:<20}: {corr_value:6.3f} ({strength} {direction})\")\n",
    "\n",
    "# Summary and Key Insights\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ KEY INSIGHTS FROM EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "insights = []\n",
    "\n",
    "# Salary insights\n",
    "avg_salary = df['salary'].mean()\n",
    "insights.append(f\"‚Ä¢ Average salary across all employees: ${avg_salary:,.0f}\")\n",
    "\n",
    "# Department insights\n",
    "highest_dept = dept_salary.index[0]\n",
    "lowest_dept = dept_salary.index[-1]\n",
    "insights.append(f\"‚Ä¢ Highest paying department: {highest_dept} (${dept_salary.loc[highest_dept, 'mean']:,.0f})\")\n",
    "insights.append(f\"‚Ä¢ Lowest paying department: {lowest_dept} (${dept_salary.loc[lowest_dept, 'mean']:,.0f})\")\n",
    "\n",
    "# Experience insights\n",
    "exp_corr = correlation_matrix.loc['years_experience', 'salary']\n",
    "insights.append(f\"‚Ä¢ Years of experience shows {exp_corr:.3f} correlation with salary\")\n",
    "\n",
    "# Performance insights\n",
    "perf_corr = correlation_matrix.loc['performance_rating', 'salary']\n",
    "insights.append(f\"‚Ä¢ Performance rating shows {perf_corr:.3f} correlation with salary\")\n",
    "\n",
    "# Age insights\n",
    "age_corr = correlation_matrix.loc['age', 'salary']\n",
    "insights.append(f\"‚Ä¢ Age shows {age_corr:.3f} correlation with salary\")\n",
    "\n",
    "# Education insights\n",
    "phd_avg = edu_salary.loc['PhD', 'mean'] if 'PhD' in edu_salary.index else 0\n",
    "hs_avg = edu_salary.loc['High School', 'mean'] if 'High School' in edu_salary.index else 0\n",
    "if phd_avg > 0 and hs_avg > 0:\n",
    "    edu_premium = ((phd_avg - hs_avg) / hs_avg) * 100\n",
    "    insights.append(f\"‚Ä¢ PhD holders earn {edu_premium:.1f}% more than High School graduates\")\n",
    "\n",
    "# Location insights\n",
    "sf_avg = loc_salary.loc['San Francisco', 'mean'] if 'San Francisco' in loc_salary.index else 0\n",
    "remote_avg = loc_salary.loc['Remote', 'mean'] if 'Remote' in loc_salary.index else 0\n",
    "if sf_avg > 0 and remote_avg > 0:\n",
    "    location_premium = ((sf_avg - remote_avg) / remote_avg) * 100\n",
    "    insights.append(f\"‚Ä¢ San Francisco employees earn {location_premium:.1f}% more than remote workers\")\n",
    "\n",
    "# Print insights\n",
    "for insight in insights:\n",
    "    print(insight)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìù RECOMMENDATIONS FOR MODEL DEVELOPMENT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "recommendations = [\n",
    "    \"‚Ä¢ Include all categorical variables (department, job_title, education, location) as features\",\n",
    "    \"‚Ä¢ Years of experience is a strong predictor - consider feature engineering\",\n",
    "    \"‚Ä¢ Performance rating shows good correlation - keep as important feature\",\n",
    "    \"‚Ä¢ Consider creating interaction features between experience and education\",\n",
    "    \"‚Ä¢ Department and job title may benefit from target encoding\",\n",
    "    \"‚Ä¢ Location premium suggests geographical factors are important\",\n",
    "    \"‚Ä¢ Consider polynomial features for experience and age\",\n",
    "    \"‚Ä¢ Salary distribution appears normal - linear models may work well\",\n",
    "    \"‚Ä¢ Low number of outliers - data quality is good\"\n",
    "]\n",
    "\n",
    "for rec in recommendations:\n",
    "    print(rec)\n",
    "\n",
    "print(\"\\nüéâ EXPLORATORY DATA ANALYSIS COMPLETE!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
